{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10447946,"sourceType":"datasetVersion","datasetId":6467052}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import backend as K\n\n# tf.compat.v1.disable_eager_execution()\n\nmodel = VGG16(weights='imagenet')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T05:27:01.340927Z","iopub.execute_input":"2025-01-12T05:27:01.341233Z","iopub.status.idle":"2025-01-12T05:27:15.255143Z","shell.execute_reply.started":"2025-01-12T05:27:01.341204Z","shell.execute_reply":"2025-01-12T05:27:15.254378Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.pixoto.com%2Fimages-photography%2Fanimals%2Fother-mammals%2Fscreaming-donky--6470543649800192&psig=AOvVaw0wy7CZeGcqUrSoB7QNZXDr&ust=1736721689346000&source=images&cd=vfe&opi=89978449&ved=2ahUKEwiWxZrM3u6KAxVezQIHHYyFPL0QjRx6BAgAEBk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:43:26.103470Z","iopub.execute_input":"2025-01-11T22:43:26.103772Z","iopub.status.idle":"2025-01-11T22:43:26.256275Z","shell.execute_reply.started":"2025-01-11T22:43:26.103750Z","shell.execute_reply":"2025-01-11T22:43:26.254878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\nimport numpy as np\n\n# The local path to our target image\nimg_path = '/kaggle/input/foximage/fox.jpg'\n\n# `img` is a PIL image of size 224x224\nimg = image.load_img(img_path, target_size=(224, 224))\n\n# `x` is a float32 Numpy array of shape (224, 224, 3)\nx = image.img_to_array(img)\n\n# We add a dimension to transform our array into a \"batch\"\n# of size (1, 224, 224, 3)\nx = np.expand_dims(x, axis=0)\n\n# Finally we preprocess the batch\n# (this does channel-wise color normalization)\nx = preprocess_input(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T05:27:15.720563Z","iopub.execute_input":"2025-01-12T05:27:15.721246Z","iopub.status.idle":"2025-01-12T05:27:15.790608Z","shell.execute_reply.started":"2025-01-12T05:27:15.721216Z","shell.execute_reply":"2025-01-12T05:27:15.789678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = model.predict(x)\nprint('Predicted:', decode_predictions(preds, top=3)[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T05:27:19.261765Z","iopub.execute_input":"2025-01-12T05:27:19.262076Z","iopub.status.idle":"2025-01-12T05:27:22.923916Z","shell.execute_reply.started":"2025-01-12T05:27:19.262050Z","shell.execute_reply":"2025-01-12T05:27:22.923173Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.argmax(preds[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T05:27:38.861754Z","iopub.execute_input":"2025-01-12T05:27:38.862104Z","iopub.status.idle":"2025-01-12T05:27:38.868313Z","shell.execute_reply.started":"2025-01-12T05:27:38.862073Z","shell.execute_reply":"2025-01-12T05:27:38.867493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:46:32.488110Z","iopub.execute_input":"2025-01-11T22:46:32.488447Z","iopub.status.idle":"2025-01-11T22:46:32.517919Z","shell.execute_reply.started":"2025-01-11T22:46:32.488414Z","shell.execute_reply":"2025-01-11T22:46:32.517031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Load pre-trained VGG16 model and the image\nmodel = VGG16(weights='imagenet')\n\n# Image preprocessing\nimg_path = '/kaggle/input/foximage/fox.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\n# Get the predicted class\npreds = model.predict(x)\npredicted_class = np.argmax(preds[0])\nprint('Predicted:', decode_predictions(preds, top=3)[0])\n\n# Get the gradients of the predicted class with respect to the output feature map of `block5_conv3`\ngrad_model = tf.keras.models.Model(\n    [model.inputs],  # Model input\n    [model.get_layer('block5_conv3').output, model.output]  # Feature map and predictions\n)\n\nwith tf.GradientTape() as tape:\n    # Watch the input\n    conv_outputs, predictions = grad_model(x)\n    loss = predictions[:, predicted_class]\n\n# Compute gradients\ngrads = tape.gradient(loss, conv_outputs)\n\n# Compute the channel-wise mean of the gradients\npooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n# Multiply each channel in the feature map array by \"how important this channel is\"\nconv_outputs = conv_outputs[0]\nheatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n\n# Normalize the heatmap to range [0, 1]\nheatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n\n# Display the heatmap\nplt.matshow(heatmap)\nplt.show()\n\n# Superimpose the heatmap onto the original image\nheatmap = cv2.resize(heatmap, (img.size[0], img.size[1])) \nheatmap = np.uint8(255 * heatmap)\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\nsuperimposed_img = cv2.addWeighted(\n    cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR), 0.6, heatmap, 0.4, 0\n)\n\n# Save the resulting image\ncv2.imwrite('/kaggle/input/foximage/fox.jpg', superimposed_img)\n\n# Show the superimposed image\nplt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T05:28:02.496644Z","iopub.execute_input":"2025-01-12T05:28:02.496937Z","iopub.status.idle":"2025-01-12T05:28:05.913840Z","shell.execute_reply.started":"2025-01-12T05:28:02.496915Z","shell.execute_reply":"2025-01-12T05:28:05.913025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n# Ensure heatmap is in float format for division\nheatmap = np.maximum(heatmap, 0).astype('float32')\n# Normalize the heatmap\nheatmap /= np.max(heatmap)\n# Display the heatmap\nplt.matshow(heatmap)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:46:44.988266Z","iopub.execute_input":"2025-01-11T22:46:44.988529Z","iopub.status.idle":"2025-01-11T22:46:45.295621Z","shell.execute_reply.started":"2025-01-11T22:46:44.988507Z","shell.execute_reply":"2025-01-11T22:46:45.294572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}